{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clothes Classification with Support Vector Machines\n",
    "\n",
    "In this notebook we are going to explore the use of Support Vector Machines (SVM) for image classification. We are going to use a new version of the famous MNIST dataset (the original is a dataset of handwritten digits). The version we are going to use is called Fashion MNIST (https://pravarmahajan.github.io/fashion/) and is a dataset of small images of clothes and accessories.\n",
    "\n",
    "\n",
    "\n",
    "The dataset labels are the following:\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Insert your surname, name and ID number\n",
    "\n",
    "Student name: Davide Maniscalco\n",
    "    \n",
    "ID: 1212063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the required packages\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to load Fashion MNIST dataset\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte.gz' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte.gz' % kind)\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,offset=8)\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,offset=16).reshape(len(labels), 784)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix your ID (\"numero di matricola\") and the seed for random generator (as usual you can try different seeds)\n",
    "ID = 1212063\n",
    "np.random.seed(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n"
     ]
    }
   ],
   "source": [
    "#load the Fashion MNIST dataset from the 'data' folder and let's normalize the features so that each value is in [0,1] \n",
    "\n",
    "X, y = load_mnist('data', kind='train')\n",
    "# rescale the data\n",
    "X, y = X / 255., y # original pixel values are between 0 and 255\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split into training and test. Make sure that each label is present at least 10 times\n",
    "in training. If it is not, then keep adding permutations to the initial data until this \n",
    "happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in training dataset:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in training dataset:  [57 53 37 47 48 50 52 53 57 46]\n"
     ]
    }
   ],
   "source": [
    "#random permute the data and split into training and test taking the first 500\n",
    "#data samples as training and the rests as test\n",
    "permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 500\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting a image and printing the corresponding label\n",
    "def plot_input(X_matrix, labels, index):\n",
    "    print(\"INPUT:\")\n",
    "    plt.imshow(\n",
    "        X_matrix[index].reshape(28,28),\n",
    "        cmap          = plt.cm.gray_r,\n",
    "        interpolation = \"nearest\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\"LABEL: %i\"%labels[index])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 3\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 6\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 1\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 8\n"
     ]
    }
   ],
   "source": [
    "#let's try the plotting function\n",
    "plot_input(X_train,y_train,5)\n",
    "plot_input(X_test,y_test,50)\n",
    "plot_input(X_test,y_test,500)\n",
    "plot_input(X_test,y_test,5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 1\n",
    "Use a SVM classifier with cross validation to pick a model. Use a 4-fold cross-validation. Let's start with a Linear kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='linear',\n",
       "                           max_iter=-1, probability=False, random_state=None,\n",
       "                           shrinking=True, tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.0005, 0.005, 0.05, 0.5, 5, 50, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import SVC\n",
    "from sklearn.svm import SVC\n",
    "#import for Cross-Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters for linear SVM\n",
    "parameters = {'C': [0.0005, 0.005, 0.05, 0.5, 5, 50, 500]}\n",
    "\n",
    "#run linear SVM\n",
    "linear = SVC(kernel='linear')\n",
    "linear_cv = GridSearchCV(linear, parameters, cv=4, return_train_score=True)\n",
    "linear_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LINEAR KERNEL\n",
      "Best parameters set found:  {'C': 0.05}\n",
      "Score with best parameters:  0.794\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.532678</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.113846</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>{'C': 0.0005}</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.016392</td>\n",
       "      <td>7</td>\n",
       "      <td>0.402703</td>\n",
       "      <td>0.402667</td>\n",
       "      <td>0.408488</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.406639</td>\n",
       "      <td>0.004225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.279664</td>\n",
       "      <td>0.006547</td>\n",
       "      <td>0.095359</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'C': 0.005}</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.739837</td>\n",
       "      <td>0.729508</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.021176</td>\n",
       "      <td>6</td>\n",
       "      <td>0.786486</td>\n",
       "      <td>0.781333</td>\n",
       "      <td>0.806366</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.792621</td>\n",
       "      <td>0.009585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.192705</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.075239</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'C': 0.05}</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>0.762295</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.021632</td>\n",
       "      <td>1</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.941645</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.945342</td>\n",
       "      <td>0.002774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.197124</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>0.076523</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 0.5}</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.024070</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.196560</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.074635</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 5}</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.729508</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.026999</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.195453</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.073794</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>50</td>\n",
       "      <td>{'C': 50}</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.729508</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.026999</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.196198</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.074248</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>500</td>\n",
       "      <td>{'C': 500}</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.729508</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.026999</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.532678      0.003801         0.113846        0.003318  0.0005   \n",
       "1       0.279664      0.006547         0.095359        0.003204   0.005   \n",
       "2       0.192705      0.000895         0.075239        0.001424    0.05   \n",
       "3       0.197124      0.002271         0.076523        0.003322     0.5   \n",
       "4       0.196560      0.002383         0.074635        0.002792       5   \n",
       "5       0.195453      0.002984         0.073794        0.002686      50   \n",
       "6       0.196198      0.001954         0.074248        0.001615     500   \n",
       "\n",
       "          params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'C': 0.0005}           0.415385              0.376           0.414634   \n",
       "1   {'C': 0.005}           0.784615              0.760           0.739837   \n",
       "2    {'C': 0.05}           0.823077              0.792           0.796748   \n",
       "3     {'C': 0.5}           0.761538              0.800           0.788618   \n",
       "4       {'C': 5}           0.761538              0.800           0.788618   \n",
       "5      {'C': 50}           0.761538              0.800           0.788618   \n",
       "6     {'C': 500}           0.761538              0.800           0.788618   \n",
       "\n",
       "   split3_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.393443            0.400        0.016392                7   \n",
       "1           0.729508            0.754        0.021176                6   \n",
       "2           0.762295            0.794        0.021632                1   \n",
       "3           0.737705            0.772        0.024070                2   \n",
       "4           0.729508            0.770        0.026999                3   \n",
       "5           0.729508            0.770        0.026999                3   \n",
       "6           0.729508            0.770        0.026999                3   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.402703            0.402667            0.408488   \n",
       "1            0.786486            0.781333            0.806366   \n",
       "2            0.945946            0.949333            0.941645   \n",
       "3            1.000000            1.000000            1.000000   \n",
       "4            1.000000            1.000000            1.000000   \n",
       "5            1.000000            1.000000            1.000000   \n",
       "6            1.000000            1.000000            1.000000   \n",
       "\n",
       "   split3_train_score  mean_train_score  std_train_score  \n",
       "0            0.412698          0.406639         0.004225  \n",
       "1            0.796296          0.792621         0.009585  \n",
       "2            0.944444          0.945342         0.002774  \n",
       "3            1.000000          1.000000         0.000000  \n",
       "4            1.000000          1.000000         0.000000  \n",
       "5            1.000000          1.000000         0.000000  \n",
       "6            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print ('RESULTS FOR LINEAR KERNEL')\n",
    "print(\"Best parameters set found: \",linear_cv.best_params_)\n",
    "print(\"Score with best parameters: \" ,linear_cv.best_score_)\n",
    "print(\"All scores on the grid:\")\n",
    "linear_scores=pd.DataFrame(linear_cv.cv_results_)           #.iloc[:,[4,10,17]]\n",
    "linear_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 2\n",
    "Pick a model for the Polynomial kernel with degree=2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR POLY DEGREE=2 KERNEL\n",
      "Best parameters set found: {'C': 0.05, 'gamma': 0.5}\n",
      "Score with best parameters: 0.778\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.220190</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.075388</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'C': 0.05, 'gamma': 0.05}</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>9</td>\n",
       "      <td>0.875676</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.883289</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.875979</td>\n",
       "      <td>0.007446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.188493</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.066946</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 0.05, 'gamma': 0.5}</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.016721</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.185189</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>0.067262</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 0.05, 'gamma': 5.0}</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.016721</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.184978</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>0.067665</td>\n",
       "      <td>0.004128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'C': 0.5, 'gamma': 0.05}</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.764228</td>\n",
       "      <td>0.745902</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.023071</td>\n",
       "      <td>8</td>\n",
       "      <td>0.989189</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.992042</td>\n",
       "      <td>0.989418</td>\n",
       "      <td>0.989996</td>\n",
       "      <td>0.001184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.185975</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>0.066526</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 0.5, 'gamma': 0.5}</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.016721</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.183367</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.065696</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 0.5, 'gamma': 5.0}</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.016721</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.181976</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'C': 5, 'gamma': 0.05}</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.016721</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.185701</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.066806</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 5, 'gamma': 0.5}</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.016721</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.184527</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.002832</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 5, 'gamma': 5.0}</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.016721</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.220190      0.004583         0.075388        0.001554    0.05   \n",
       "1       0.188493      0.005387         0.066946        0.003356    0.05   \n",
       "2       0.185189      0.003142         0.067262        0.003411    0.05   \n",
       "3       0.184978      0.004659         0.067665        0.004128     0.5   \n",
       "4       0.185975      0.003204         0.066526        0.002968     0.5   \n",
       "5       0.183367      0.002446         0.065696        0.002394     0.5   \n",
       "6       0.181976      0.003576         0.067514        0.005409       5   \n",
       "7       0.185701      0.002715         0.066806        0.004086       5   \n",
       "8       0.184527      0.002769         0.067024        0.002832       5   \n",
       "\n",
       "  param_gamma                      params  split0_test_score  \\\n",
       "0        0.05  {'C': 0.05, 'gamma': 0.05}           0.723077   \n",
       "1         0.5   {'C': 0.05, 'gamma': 0.5}           0.784615   \n",
       "2           5   {'C': 0.05, 'gamma': 5.0}           0.784615   \n",
       "3        0.05   {'C': 0.5, 'gamma': 0.05}           0.807692   \n",
       "4         0.5    {'C': 0.5, 'gamma': 0.5}           0.784615   \n",
       "5           5    {'C': 0.5, 'gamma': 5.0}           0.784615   \n",
       "6        0.05     {'C': 5, 'gamma': 0.05}           0.784615   \n",
       "7         0.5      {'C': 5, 'gamma': 0.5}           0.784615   \n",
       "8           5      {'C': 5, 'gamma': 5.0}           0.784615   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0              0.744           0.723577           0.688525            0.720   \n",
       "1              0.800           0.772358           0.754098            0.778   \n",
       "2              0.800           0.772358           0.754098            0.778   \n",
       "3              0.784           0.764228           0.745902            0.776   \n",
       "4              0.800           0.772358           0.754098            0.778   \n",
       "5              0.800           0.772358           0.754098            0.778   \n",
       "6              0.800           0.772358           0.754098            0.778   \n",
       "7              0.800           0.772358           0.754098            0.778   \n",
       "8              0.800           0.772358           0.754098            0.778   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.019782                9            0.875676            0.864000   \n",
       "1        0.016721                1            1.000000            1.000000   \n",
       "2        0.016721                1            1.000000            1.000000   \n",
       "3        0.023071                8            0.989189            0.989333   \n",
       "4        0.016721                1            1.000000            1.000000   \n",
       "5        0.016721                1            1.000000            1.000000   \n",
       "6        0.016721                1            1.000000            1.000000   \n",
       "7        0.016721                1            1.000000            1.000000   \n",
       "8        0.016721                1            1.000000            1.000000   \n",
       "\n",
       "   split2_train_score  split3_train_score  mean_train_score  std_train_score  \n",
       "0            0.883289            0.880952          0.875979         0.007446  \n",
       "1            1.000000            1.000000          1.000000         0.000000  \n",
       "2            1.000000            1.000000          1.000000         0.000000  \n",
       "3            0.992042            0.989418          0.989996         0.001184  \n",
       "4            1.000000            1.000000          1.000000         0.000000  \n",
       "5            1.000000            1.000000          1.000000         0.000000  \n",
       "6            1.000000            1.000000          1.000000         0.000000  \n",
       "7            1.000000            1.000000          1.000000         0.000000  \n",
       "8            1.000000            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters for poly with degree 2 kernel\n",
    "parameters = {'C': [0.05, 0.5, 5],'gamma':[0.05,0.5,5.]}\n",
    "\n",
    "poly = SVC(kernel='poly',degree = 2)\n",
    "poly_cv = GridSearchCV(poly, parameters, cv=4, return_train_score=True)\n",
    "poly_cv.fit(X_train,y_train)\n",
    "\n",
    "print ('RESULTS FOR POLY DEGREE=2 KERNEL')\n",
    "print(\"Best parameters set found:\",poly_cv.best_params_)\n",
    "print(\"Score with best parameters:\",poly_cv.best_score_)\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "\n",
    "poly_scores=pd.DataFrame(poly_cv.cv_results_)    #.iloc[:,[4,10,17]]\n",
    "poly_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 3\n",
    "\n",
    "Now let's try a higher degree for the polynomial kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR POLY DEGREE= 3  KERNEL\n",
      "Best parameters set found: {'C': 0.5, 'gamma': 0.05}\n",
      "Score with best parameters: 0.756\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.191960</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>0.064265</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'C': 0.05, 'gamma': 0.05}</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.021117</td>\n",
       "      <td>9</td>\n",
       "      <td>0.951351</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.960212</td>\n",
       "      <td>0.949735</td>\n",
       "      <td>0.951325</td>\n",
       "      <td>0.005813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.168599</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.060682</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 0.05, 'gamma': 0.5}</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.032034</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.168816</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.060507</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 0.05, 'gamma': 5.0}</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.032034</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.175283</td>\n",
       "      <td>0.004786</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'C': 0.5, 'gamma': 0.05}</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.033095</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.994665</td>\n",
       "      <td>0.003253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.168888</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>0.060577</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 0.5, 'gamma': 0.5}</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.032034</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.170005</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>0.062347</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 0.5, 'gamma': 5.0}</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.032034</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.170957</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.062751</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'C': 5, 'gamma': 0.05}</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.032034</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.168583</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.061010</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 5, 'gamma': 0.5}</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.032034</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.169604</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>0.062299</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 5, 'gamma': 5.0}</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.032034</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.191960      0.002572         0.064265        0.002219    0.05   \n",
       "1       0.168599      0.003665         0.060682        0.002297    0.05   \n",
       "2       0.168816      0.003623         0.060507        0.002181    0.05   \n",
       "3       0.175283      0.004786         0.064100        0.004174     0.5   \n",
       "4       0.168888      0.004197         0.060577        0.001857     0.5   \n",
       "5       0.170005      0.003981         0.062347        0.002163     0.5   \n",
       "6       0.170957      0.003974         0.062751        0.002794       5   \n",
       "7       0.168583      0.003048         0.061010        0.001239       5   \n",
       "8       0.169604      0.004346         0.062299        0.001672       5   \n",
       "\n",
       "  param_gamma                      params  split0_test_score  \\\n",
       "0        0.05  {'C': 0.05, 'gamma': 0.05}           0.738462   \n",
       "1         0.5   {'C': 0.05, 'gamma': 0.5}           0.784615   \n",
       "2           5   {'C': 0.05, 'gamma': 5.0}           0.784615   \n",
       "3        0.05   {'C': 0.5, 'gamma': 0.05}           0.792308   \n",
       "4         0.5    {'C': 0.5, 'gamma': 0.5}           0.784615   \n",
       "5           5    {'C': 0.5, 'gamma': 5.0}           0.784615   \n",
       "6        0.05     {'C': 5, 'gamma': 0.05}           0.784615   \n",
       "7         0.5      {'C': 5, 'gamma': 0.5}           0.784615   \n",
       "8           5      {'C': 5, 'gamma': 5.0}           0.784615   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0              0.752           0.715447           0.696721            0.726   \n",
       "1              0.760           0.747967           0.696721            0.748   \n",
       "2              0.760           0.747967           0.696721            0.748   \n",
       "3              0.776           0.747967           0.704918            0.756   \n",
       "4              0.760           0.747967           0.696721            0.748   \n",
       "5              0.760           0.747967           0.696721            0.748   \n",
       "6              0.760           0.747967           0.696721            0.748   \n",
       "7              0.760           0.747967           0.696721            0.748   \n",
       "8              0.760           0.747967           0.696721            0.748   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.021117                9            0.951351               0.944   \n",
       "1        0.032034                2            1.000000               1.000   \n",
       "2        0.032034                2            1.000000               1.000   \n",
       "3        0.033095                1            0.994595               0.992   \n",
       "4        0.032034                2            1.000000               1.000   \n",
       "5        0.032034                2            1.000000               1.000   \n",
       "6        0.032034                2            1.000000               1.000   \n",
       "7        0.032034                2            1.000000               1.000   \n",
       "8        0.032034                2            1.000000               1.000   \n",
       "\n",
       "   split2_train_score  split3_train_score  mean_train_score  std_train_score  \n",
       "0            0.960212            0.949735          0.951325         0.005813  \n",
       "1            1.000000            1.000000          1.000000         0.000000  \n",
       "2            1.000000            1.000000          1.000000         0.000000  \n",
       "3            1.000000            0.992063          0.994665         0.003253  \n",
       "4            1.000000            1.000000          1.000000         0.000000  \n",
       "5            1.000000            1.000000          1.000000         0.000000  \n",
       "6            1.000000            1.000000          1.000000         0.000000  \n",
       "7            1.000000            1.000000          1.000000         0.000000  \n",
       "8            1.000000            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters for poly with higher degree kernel\n",
    "parameters = {'C': [0.05, 0.5, 5],'gamma':[0.05,0.5,5.]}\n",
    "\n",
    "#run SVM with poly of higher degree kernel\n",
    "degree = 3\n",
    "poly3 = SVC(kernel='poly',degree = degree)\n",
    "poly3_cv = GridSearchCV(poly3, parameters, cv=4, return_train_score=True)\n",
    "poly3_cv.fit(X_train,y_train)\n",
    "\n",
    "print ('RESULTS FOR POLY DEGREE=', degree, ' KERNEL')\n",
    "print(\"Best parameters set found:\",poly3_cv.best_params_)\n",
    "print(\"Score with best parameters:\",poly3_cv.best_score_)\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "\n",
    "poly3_scores=pd.DataFrame(poly3_cv.cv_results_)\n",
    "poly3_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 4\n",
    "Pick a model for the Radial Basis Function kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR rbf KERNEL\n",
      "Best parameters set found: {'C': 5, 'gamma': 0.005}\n",
      "Score with best parameters: 0.786\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341491</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0.103617</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'C': 0.5, 'gamma': 0.005}</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.713115</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.026099</td>\n",
       "      <td>7</td>\n",
       "      <td>0.786486</td>\n",
       "      <td>0.778667</td>\n",
       "      <td>0.782493</td>\n",
       "      <td>0.806878</td>\n",
       "      <td>0.788631</td>\n",
       "      <td>0.010892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.564161</td>\n",
       "      <td>0.010935</td>\n",
       "      <td>0.106984</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'C': 0.5, 'gamma': 0.05}</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.647541</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.028664</td>\n",
       "      <td>8</td>\n",
       "      <td>0.905405</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.901857</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.905990</td>\n",
       "      <td>0.004074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.593575</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 0.5, 'gamma': 0.5}</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.113821</td>\n",
       "      <td>0.122951</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>13</td>\n",
       "      <td>0.235135</td>\n",
       "      <td>0.237333</td>\n",
       "      <td>0.233422</td>\n",
       "      <td>0.232804</td>\n",
       "      <td>0.234674</td>\n",
       "      <td>0.001757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.615877</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.124013</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 0.5, 'gamma': 5}</td>\n",
       "      <td>0.223077</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.227642</td>\n",
       "      <td>0.221311</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.007297</td>\n",
       "      <td>9</td>\n",
       "      <td>0.227027</td>\n",
       "      <td>0.229333</td>\n",
       "      <td>0.228117</td>\n",
       "      <td>0.227513</td>\n",
       "      <td>0.227998</td>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.241545</td>\n",
       "      <td>0.006025</td>\n",
       "      <td>0.084853</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'C': 5, 'gamma': 0.005}</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.033065</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956757</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.954907</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.955345</td>\n",
       "      <td>0.001932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.591445</td>\n",
       "      <td>0.010659</td>\n",
       "      <td>0.111938</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'C': 5, 'gamma': 0.05}</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.031477</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.610254</td>\n",
       "      <td>0.010119</td>\n",
       "      <td>0.116307</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 5, 'gamma': 0.5}</td>\n",
       "      <td>0.161538</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.139344</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.619614</td>\n",
       "      <td>0.009822</td>\n",
       "      <td>0.118845</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 5, 'gamma': 5}</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.113821</td>\n",
       "      <td>0.122951</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.246592</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>0.083014</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>50</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'C': 50, 'gamma': 0.005}</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.028371</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.591030</td>\n",
       "      <td>0.014337</td>\n",
       "      <td>0.109729</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>50</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'C': 50, 'gamma': 0.05}</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.031477</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.607528</td>\n",
       "      <td>0.012602</td>\n",
       "      <td>0.113463</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 50, 'gamma': 0.5}</td>\n",
       "      <td>0.161538</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.139344</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.620655</td>\n",
       "      <td>0.010355</td>\n",
       "      <td>0.119122</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 50, 'gamma': 5}</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.113821</td>\n",
       "      <td>0.122951</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.245598</td>\n",
       "      <td>0.005893</td>\n",
       "      <td>0.083066</td>\n",
       "      <td>0.002903</td>\n",
       "      <td>500</td>\n",
       "      <td>0.005</td>\n",
       "      <td>{'C': 500, 'gamma': 0.005}</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.028371</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.588102</td>\n",
       "      <td>0.009925</td>\n",
       "      <td>0.108489</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'C': 500, 'gamma': 0.05}</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.031477</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.606686</td>\n",
       "      <td>0.012504</td>\n",
       "      <td>0.115092</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 500, 'gamma': 0.5}</td>\n",
       "      <td>0.161538</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.139344</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.620392</td>\n",
       "      <td>0.012032</td>\n",
       "      <td>0.118008</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 500, 'gamma': 5}</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.113821</td>\n",
       "      <td>0.122951</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.341491      0.005492         0.103617        0.003090     0.5   \n",
       "1        0.564161      0.010935         0.106984        0.003303     0.5   \n",
       "2        0.593575      0.009931         0.111864        0.002316     0.5   \n",
       "3        0.615877      0.005029         0.124013        0.005045     0.5   \n",
       "4        0.241545      0.006025         0.084853        0.002075       5   \n",
       "5        0.591445      0.010659         0.111938        0.003910       5   \n",
       "6        0.610254      0.010119         0.116307        0.005531       5   \n",
       "7        0.619614      0.009822         0.118845        0.002716       5   \n",
       "8        0.246592      0.006580         0.083014        0.002324      50   \n",
       "9        0.591030      0.014337         0.109729        0.003801      50   \n",
       "10       0.607528      0.012602         0.113463        0.003269      50   \n",
       "11       0.620655      0.010355         0.119122        0.001834      50   \n",
       "12       0.245598      0.005893         0.083066        0.002903     500   \n",
       "13       0.588102      0.009925         0.108489        0.005081     500   \n",
       "14       0.606686      0.012504         0.115092        0.002069     500   \n",
       "15       0.620392      0.012032         0.118008        0.001788     500   \n",
       "\n",
       "   param_gamma                      params  split0_test_score  \\\n",
       "0        0.005  {'C': 0.5, 'gamma': 0.005}           0.776923   \n",
       "1         0.05   {'C': 0.5, 'gamma': 0.05}           0.676923   \n",
       "2          0.5    {'C': 0.5, 'gamma': 0.5}           0.130769   \n",
       "3            5      {'C': 0.5, 'gamma': 5}           0.223077   \n",
       "4        0.005    {'C': 5, 'gamma': 0.005}           0.823077   \n",
       "5         0.05     {'C': 5, 'gamma': 0.05}           0.746154   \n",
       "6          0.5      {'C': 5, 'gamma': 0.5}           0.161538   \n",
       "7            5        {'C': 5, 'gamma': 5}           0.130769   \n",
       "8        0.005   {'C': 50, 'gamma': 0.005}           0.769231   \n",
       "9         0.05    {'C': 50, 'gamma': 0.05}           0.746154   \n",
       "10         0.5     {'C': 50, 'gamma': 0.5}           0.161538   \n",
       "11           5       {'C': 50, 'gamma': 5}           0.130769   \n",
       "12       0.005  {'C': 500, 'gamma': 0.005}           0.769231   \n",
       "13        0.05   {'C': 500, 'gamma': 0.05}           0.746154   \n",
       "14         0.5    {'C': 500, 'gamma': 0.5}           0.161538   \n",
       "15           5      {'C': 500, 'gamma': 5}           0.130769   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0               0.760           0.723577           0.713115            0.744   \n",
       "1               0.728           0.682927           0.647541            0.684   \n",
       "2               0.112           0.113821           0.122951            0.120   \n",
       "3               0.208           0.227642           0.221311            0.220   \n",
       "4               0.808           0.772358           0.737705            0.786   \n",
       "5               0.808           0.756098           0.721311            0.758   \n",
       "6               0.176           0.178862           0.139344            0.164   \n",
       "7               0.112           0.113821           0.122951            0.120   \n",
       "8               0.816           0.788618           0.737705            0.778   \n",
       "9               0.808           0.756098           0.721311            0.758   \n",
       "10              0.176           0.178862           0.139344            0.164   \n",
       "11              0.112           0.113821           0.122951            0.120   \n",
       "12              0.816           0.788618           0.737705            0.778   \n",
       "13              0.808           0.756098           0.721311            0.758   \n",
       "14              0.176           0.178862           0.139344            0.164   \n",
       "15              0.112           0.113821           0.122951            0.120   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.026099                7            0.786486            0.778667   \n",
       "1         0.028664                8            0.905405            0.904000   \n",
       "2         0.007594               13            0.235135            0.237333   \n",
       "3         0.007297                9            0.227027            0.229333   \n",
       "4         0.033065                1            0.956757            0.957333   \n",
       "5         0.031477                4            1.000000            1.000000   \n",
       "6         0.015500               10            1.000000            1.000000   \n",
       "7         0.007594               13            1.000000            1.000000   \n",
       "8         0.028371                2            1.000000            1.000000   \n",
       "9         0.031477                4            1.000000            1.000000   \n",
       "10        0.015500               10            1.000000            1.000000   \n",
       "11        0.007594               13            1.000000            1.000000   \n",
       "12        0.028371                2            1.000000            1.000000   \n",
       "13        0.031477                4            1.000000            1.000000   \n",
       "14        0.015500               10            1.000000            1.000000   \n",
       "15        0.007594               13            1.000000            1.000000   \n",
       "\n",
       "    split2_train_score  split3_train_score  mean_train_score  std_train_score  \n",
       "0             0.782493            0.806878          0.788631         0.010892  \n",
       "1             0.901857            0.912698          0.905990         0.004074  \n",
       "2             0.233422            0.232804          0.234674         0.001757  \n",
       "3             0.228117            0.227513          0.227998         0.000862  \n",
       "4             0.954907            0.952381          0.955345         0.001932  \n",
       "5             1.000000            1.000000          1.000000         0.000000  \n",
       "6             1.000000            1.000000          1.000000         0.000000  \n",
       "7             1.000000            1.000000          1.000000         0.000000  \n",
       "8             1.000000            1.000000          1.000000         0.000000  \n",
       "9             1.000000            1.000000          1.000000         0.000000  \n",
       "10            1.000000            1.000000          1.000000         0.000000  \n",
       "11            1.000000            1.000000          1.000000         0.000000  \n",
       "12            1.000000            1.000000          1.000000         0.000000  \n",
       "13            1.000000            1.000000          1.000000         0.000000  \n",
       "14            1.000000            1.000000          1.000000         0.000000  \n",
       "15            1.000000            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters for rbf SVM\n",
    "parameters = {'C': [0.5, 5, 50, 500],'gamma':[0.005, 0.05, 0.5,5]}\n",
    "\n",
    "rbf = SVC(kernel='rbf')\n",
    "rbf_cv = GridSearchCV(rbf, parameters, cv=4, return_train_score=True)\n",
    "rbf_cv.fit(X_train,y_train)\n",
    "\n",
    "print ('RESULTS FOR rbf KERNEL')\n",
    "print(\"Best parameters set found:\",rbf_cv.best_params_)\n",
    "print(\"Score with best parameters:\",rbf_cv.best_score_)\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "\n",
    "rbf_scores=pd.DataFrame(rbf_cv.cv_results_)\n",
    "rbf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO5\n",
    "What do you observe when using RBF and polynomial kernels on this dataset ?\n",
    "\n",
    "The polinomial kernels have scores worse than the linear (and the RBF) one, but the scores are less dependent by the parameter: even very different parameters lead to similar scores. The linear kernel also shows this behaviour. This is not the case for the RBF kernel, that however presents a better score than polynomial kernels for the best C, and we are interest in using the best C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 6\n",
    "The best score is the one of the linear kernel. However, in what follows it will be used the RBF one, that a posteriori shows *much* better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR rbf KERNEL\n",
      "Best parameters set found: {'C': 5, 'gamma': 0.005}\n",
      "Score with best parameters: 0.786\n",
      "\n",
      "\n",
      "RESULTS FOR LINEAR KERNEL\n",
      "Best parameters set found:  {'C': 0.05}\n",
      "Score with best parameters:  0.794\n"
     ]
    }
   ],
   "source": [
    "print ('RESULTS FOR rbf KERNEL')\n",
    "print(\"Best parameters set found:\",rbf_cv.best_params_)\n",
    "print(\"Score with best parameters:\",rbf_cv.best_score_)\n",
    "print('\\n')\n",
    "print ('RESULTS FOR LINEAR KERNEL')\n",
    "print(\"Best parameters set found: \",linear_cv.best_params_)\n",
    "print(\"Score with best parameters: \" ,linear_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM training error: 0.046000\n",
      "Best SVM test error: 0.200084\n"
     ]
    }
   ],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "best_SVM = SVC(C=rbf_cv.best_params_['C'],gamma=rbf_cv.best_params_['gamma'])\n",
    "best_SVM.fit(X_train,y_train)\n",
    "\n",
    "training_error = 1. - best_SVM.score(X_train,y_train)\n",
    "test_error = 1. - best_SVM.score(X_test,y_test)\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data\n",
    "Now let's do the same but using more data points for training.\n",
    "\n",
    "\n",
    "Choose a new number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in training dataset:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in training dataset:  [216 207 202 199 189 201 208 190 189 199]\n"
     ]
    }
   ],
   "source": [
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 2000 # TODO number of data points, adjust depending on the capabilities of your PC\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to use SVM with parameters obtained from the best model for $m_{training} =  2000$. Since it may take a long time to run, you can decide to just let it run for some time and stop it if it does not complete. If you decide to do this, report it in the TO DO 9 cell below.\n",
    "\n",
    "### TO DO 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.005, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "\n",
    "best_SVM = SVC(C=rbf_cv.best_params_['C'],gamma=rbf_cv.best_params_['gamma'])\n",
    "best_SVM.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM training error: 0.059500\n",
      "Best SVM test error: 0.165414\n"
     ]
    }
   ],
   "source": [
    "training_error = 1. - best_SVM.score(X_train,y_train)\n",
    "test_error = 1. - best_SVM.score(X_test,y_test)\n",
    "\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for comparison, let's also use logistic regression (with standard parameters from scikit-learn, i.e. some regularization is included).\n",
    "\n",
    "### TO DO 8 Try first without regularization (use a very large large C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/davide/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression training error: 0.000000\n",
      "Best logistic regression test error: 0.232621\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "LRnoreg = linear_model.LogisticRegression(C=1e8)\n",
    "LRnoreg.fit(X_train,y_train)\n",
    "\n",
    "training_error = 1. - LRnoreg.score(X_train,y_train)\n",
    "test_error = 1. - LRnoreg.score(X_test,y_test)\n",
    "\n",
    "print (\"Best logistic regression training error: %f\" % training_error)\n",
    "print (\"Best logistic regression test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO 9 Then use also some regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/davide/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression training error: 0.037000\n",
      "Best logistic regression test error: 0.184017\n"
     ]
    }
   ],
   "source": [
    "LRreg = linear_model.LogisticRegression()\n",
    "LRreg.fit(X_train,y_train)\n",
    "\n",
    "training_error = 1. - LRreg.score(X_train,y_train)\n",
    "test_error = 1. - LRreg.score(X_test,y_test)\n",
    "\n",
    "print (\"Best logistic regression training error: %f\" % training_error)\n",
    "print (\"Best logistic regression test error: %f\" % test_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 10\n",
    "Compare and discuss:\n",
    "- the results from SVM with m=500 and with m=2000 training data points. If you stopped the SVM, include such aspect in your comparison.\n",
    "- the results of SVM and of Logistic Regression with and without regularization\n",
    "\n",
    "\n",
    "The training error remained almost the same (it passed from 0.046 to 0.05) while the test error decreased. This is what is expected: more training data lead to a better learning.\n",
    "\n",
    "Concerning the logistic regression, the case without regularization has 0 training error (that leads to think that an overfitting may be present) and a test error about 0.23. Instead, the case with the regularization shows a few larger training error but a smaller test error: this model is better, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 10\n",
    "Plot an item of clothing that is missclassified by logistic regression and correctly classified by SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_prediction = LRreg.predict(X_test)\n",
    "SVM_prediction = best_SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((LR_prediction != y_test) & (SVM_prediction == y_test))\n",
    "indices = [ii for ii in range(len(mask)) if(mask[ii]==True)]\n",
    "item = np.random.choice(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 0\n",
      "Label predicted by LR: 3\n",
      "Label predicted by SVM: 0\n"
     ]
    }
   ],
   "source": [
    "plot_input(X_test,y_test,item)\n",
    "print('Label predicted by LR:',LR_prediction[item])\n",
    "print('Label predicted by SVM:',SVM_prediction[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 11\n",
    "Plot the confusion matrix for the SVM classifier and for logistic regression.\n",
    "The confusion matrix has one column for each predicted label and one row for each true label. \n",
    "It shows for each class in the corresponding row how many samples belonging to that class gets each possible output label.\n",
    "Notice that the diagonal contains the correctly classified samples, while the other cells correspond to errors.\n",
    "You can obtain it with the sklearn.metrics.confusion_matrix function (see the documentation).\n",
    "Try also to normalize the confusion matrix by the number of samples in each class in order to measure the accuracy on each single class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and frequencies in test set:  [5784 5793 5798 5801 5811 5799 5792 5810 5811 5801]\n",
      "\n",
      " Confusion matrix SVM  \n",
      " \n",
      " [[4970    6   93  168   19    5  456    0   66    1]\n",
      " [  41 5483   60  166    6    1   33    0    3    0]\n",
      " [  93    5 4348   48  517    4  750    0   33    0]\n",
      " [ 415   39   40 4855  227    0  203    0   21    1]\n",
      " [  19    4  729  265 4105    1  667    0   20    1]\n",
      " [   9    0    0    4    0 5280    4  315   31  156]\n",
      " [1223    8  653  114  426    2 3273    0   90    3]\n",
      " [   0    0    0    0    0  320    0 5144   13  333]\n",
      " [  28    2   41   78   22   36  114   31 5450    9]\n",
      " [   0    0    1    7    0   97    2  194    2 5498]]\n",
      "\n",
      " Confusion matrix SVM (normalized)   \n",
      " \n",
      " [[0.86 0.   0.02 0.03 0.   0.   0.08 0.   0.01 0.  ]\n",
      " [0.01 0.95 0.01 0.03 0.   0.   0.01 0.   0.   0.  ]\n",
      " [0.02 0.   0.75 0.01 0.09 0.   0.13 0.   0.01 0.  ]\n",
      " [0.07 0.01 0.01 0.84 0.04 0.   0.03 0.   0.   0.  ]\n",
      " [0.   0.   0.13 0.05 0.71 0.   0.11 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.91 0.   0.05 0.01 0.03]\n",
      " [0.21 0.   0.11 0.02 0.07 0.   0.57 0.   0.02 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.06 0.   0.89 0.   0.06]\n",
      " [0.   0.   0.01 0.01 0.   0.01 0.02 0.01 0.94 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.02 0.   0.03 0.   0.95]]\n",
      "\n",
      " Confusion matrix LR  \n",
      " \n",
      " [[4586   26  171  267   37    5  559    0  127    6]\n",
      " [  22 5478   65  157   20    1   41    2    7    0]\n",
      " [ 109   10 4318   63  606    6  624    0   61    1]\n",
      " [ 305   54  105 4872  232    0  192    3   36    2]\n",
      " [  33    9  894  269 3759    1  795    0   49    2]\n",
      " [  10    2    1    4    4 5071   12  336   90  269]\n",
      " [ 932   14  760  193  576    4 3173    1  135    4]\n",
      " [   0    0    0    0    0  229    0 5185   20  376]\n",
      " [  52    2   49   95   40   59  105   31 5368   10]\n",
      " [   1    0    1    1    0   84    5  185    7 5517]]\n",
      "\n",
      " Confusion matrix LR (normalized)   \n",
      " \n",
      " [[0.79 0.   0.03 0.05 0.01 0.   0.1  0.   0.02 0.  ]\n",
      " [0.   0.95 0.01 0.03 0.   0.   0.01 0.   0.   0.  ]\n",
      " [0.02 0.   0.74 0.01 0.1  0.   0.11 0.   0.01 0.  ]\n",
      " [0.05 0.01 0.02 0.84 0.04 0.   0.03 0.   0.01 0.  ]\n",
      " [0.01 0.   0.15 0.05 0.65 0.   0.14 0.   0.01 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.87 0.   0.06 0.02 0.05]\n",
      " [0.16 0.   0.13 0.03 0.1  0.   0.55 0.   0.02 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.04 0.   0.89 0.   0.06]\n",
      " [0.01 0.   0.01 0.02 0.01 0.01 0.02 0.01 0.92 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.01 0.   0.03 0.   0.95]]\n"
     ]
    }
   ],
   "source": [
    "# for better aligned printing of confusion matrix use floatmode='fixed' (not supported in all versions of Python)\n",
    "np.set_printoptions(precision=2, suppress=True) \n",
    "\n",
    "u, counts = np.unique(y_test, return_counts=True)\n",
    "print(\"Labels and frequencies in test set: \", counts)\n",
    "\n",
    "confusion_SVM = skm.confusion_matrix(y_test, SVM_prediction)\n",
    "print(\"\\n Confusion matrix SVM  \\n \\n\", confusion_SVM)\n",
    "print(\"\\n Confusion matrix SVM (normalized)   \\n \\n\", confusion_SVM /counts[:,None] )\n",
    "\n",
    "confusion_LR = skm.confusion_matrix(y_test, LR_prediction)\n",
    "print(\"\\n Confusion matrix LR  \\n \\n\", confusion_LR)\n",
    "print(\"\\n Confusion matrix LR (normalized)   \\n \\n\", confusion_LR /counts[:,None] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 12\n",
    "Have a look at the confusion matrices and comment on the obtained accuracies. Why some classes have lower accuracies and others an higher one ? Make some guesses on the possible causes.\n",
    "\n",
    "### ANSWER TO THE QUESTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the diagonal elements, we can see that some classes are very well classified (e.g. 0,1,3,5,7,8,9) some others a bit worse (e.g. 2,4) and one very badly (6). The 6-th class is the one of the shirt, and it can be seen that a very big number (about 1/3 of the correctly classified ones) of shirt-samples are classified as t-shirts. This is probably due to the similarity between these, but the shirts have a much higher score (the shirt pattern has been learned well). Also the other misclassifications are due to similarities between the clothes: often pullovers (class 2) are classified as coats (class 4) and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
